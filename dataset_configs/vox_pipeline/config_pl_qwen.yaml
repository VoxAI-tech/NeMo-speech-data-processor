documentation: |
  Vox Pipeline - BK Poland Drive-thru Audio Dataset Creation (Qwen LLM Version)
  =============================================================================
  
  Overview
  --------
  This configuration processes drive-thru audio conversations from Burger King Poland.
  Uses Qwen LLM for menu correction instead of Gemini audio verification (faster).
  Handles Polish language audio with customer (mic) and staff (spk) channels.
  
  Data Structure:
  - Input: data/audio/bk/{device_id}/{year}/{month}/{day}/{hour}/{session_id}/{mic.wav, spk.wav}
  - Each session has two WAV files: mic (customer) and spk (employee)
  
  Pipeline Stages:
  1. Create initial manifest from drive-thru audio directory
    3. Language detection and filtering (Polish)
  2. Two-pass Whisper transcription (segments + slice-by-offset)
  3. Hallucination detection and filtering
  4. Menu fuzzy matching (first pass correction)
  5. Gemini audio verification (listen to audio for spelling corrections)
  6. Qwen punctuation/capitalization restoration
  7. Text normalization with regex
  8. Optional conversion to tarred dataset
  9. Output final manifest with all metadata
  
  Usage:
    python main.py \
      --config-path dataset_configs/vox_pipeline/ \
      --config-name config_pl_qwen.yaml \
      data_dir=data/audio \
      output_dir=outputs/vox_pipeline_pl \
      sdp_dir=/path/to/NeMo-speech-data-processor

# Base configuration paths
data_dir: ???  # Required: Path to raw audio data
output_dir: ???  # Required: Path where outputs will be saved
sdp_dir: ???  # Required: Path to NeMo-speech-data-processor repo
cache_dir: ${output_dir}/cache

# Brand and country configuration
brand: bk  # Burger King
country: pl  # Poland

# Processing parameters
params:
  audio_channel: mic  # 'mic' for customer or 'spk' for employee
  max_samples: -1  # Testing with 10 samples
  source_lang: pl  # Polish
  source_lang_full: Polish
  min_audio_lid_probability: 0.7
  min_audio_duration: 0.5  # seconds
  max_audio_duration: 30  # seconds
  use_regex: common  # Options: common, all
  convert_to_audio_tarred_dataset:
    should_run: false
    num_shards: 1
    buckets_num: 1
  save_disk_space: false  # If true, removes intermediate files

# Which processors to run
processors_to_run: all

# Use Dask for parallel processing
use_dask: false  # Set to false to avoid import issues

# Pipeline processors
processors:
  # ========== STAGE 0: Create initial manifest from Vox directory structure ==========
  - _target_: sdp.processors.datasets.vox.create_initial_manifest.CreateInitialManifestVox
    raw_data_dir: ${data_dir}
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_00.json
    brand_code: bk  # Burger King
    country_code: pl  # Poland
    brand_name: Burger King
    country_name: Poland
    speaker: ${params.audio_channel}  # mic or spk

  # ========== STAGE 1: Create unique audio ID ==========
  - _target_: sdp.processors.LambdaExpression
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_00.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_01.json
    new_field: audio_id
    expression: 'entry.device_id + "/" + entry.session_id + "/" + ("mic" if entry.audio_type == "customer" else "spk")'

  # ========== STAGE 2: Limit samples for testing (optional) ==========
  - _target_: sdp.processors.modify_manifest.limit_samples.LimitManifestEntries
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_01.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_02.json
    max_entries: ${params.max_samples}


  # ========== STAGE 3: Get audio duration ==========
  - _target_: sdp.processors.GetAudioDuration
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_02.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_02.json
    audio_filepath_key: audio_filepath
    duration_key: duration

  # ========== STAGE 3: Language detection with Whisper ==========
  - _target_: sdp.processors.FasterWhisperInference
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_02.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_02.json
    model_size_or_path: large-v3
    num_devices: -1  # Use all available GPUs
    output_dir: ${output_dir}/${params.source_lang}/step_05
    language_detection_only: true
    inference:
      language_detection_segments: 7
      chunk_length: 30
    save_timestamps_separately: false
    skip_corrupted_audios: true

  # ========== STAGE 3: Filter by language (Polish) ==========
  - _target_: sdp.processors.LambdaExpression
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_02.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_03.json
    new_field: lid_verified
    expression: '(entry.language == "${params.source_lang}") & (entry.language_probability >= ${params.min_audio_lid_probability})'
    filter: true

  # ========== STAGE 3: Drop language detection fields ==========
  - _target_: sdp.processors.DropSpecifiedFields
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_03.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_04.json
    fields_to_drop:
      - language
      - language_probability
      - lid_verified

  # ========== STAGE 3: Full transcription with segments ==========
  - _target_: sdp.processors.FasterWhisperInference
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_04.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_05.json
    model_size_or_path: VoxAI/whisper-large-v3-polish-ct2
    output_dir: ${output_dir}/${params.source_lang}/step_08
    num_devices: -1
    inference:
      language: ${params.source_lang}
    save_timestamps_separately: false
    skip_corrupted_audios: true

  # ========== STAGE 3: Drop duration (will be recalculated per segment) ==========
  - _target_: sdp.processors.DropSpecifiedFields
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_05.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_06.json
    fields_to_drop:
      - duration

  # ========== STAGE 9.5: Filter out entries with empty segments ==========
  - _target_: sdp.processors.LambdaExpression
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_06.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_07_filtered.json
    new_field: has_segments
    expression: 'len(entry.segments) > 0'
    filter: true

  # ========== STAGE 3: Convert segments list to individual entries ==========
  - _target_: sdp.processors.ListToEntries
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_07_filtered.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_08.json
    field_with_list: segments

  # ========== STAGE 3: Keep only needed segment fields ==========
  - _target_: sdp.processors.KeepOnlySpecifiedFields
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_08.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_09.json
    fields_to_keep:
      - audio_filepath
      - id
      - start
      - end
      - text
      - language
      - session_id
      - device_id
      - audio_type
      - audio_id

  # ========== STAGE 3: Calculate segment duration ==========
  - _target_: sdp.processors.LambdaExpression
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_09.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_10.json
    new_field: duration
    expression: 'entry.end - entry.start'

  # ========== STAGE 3: Filter by duration ==========
  - _target_: sdp.processors.DropHighLowDuration
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_10.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_11.json
    high_duration_threshold: ${params.max_audio_duration}
    low_duration_threshold: ${params.min_audio_duration}

  # ========== STAGE 3: Rename fields for segments ==========
  - _target_: sdp.processors.RenameFields
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_11.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_12.json
    rename_fields:
      start: offset
      id: segment_id
      language: source_lang

  # ========== STAGE 3: Keep core fields ==========
  - _target_: sdp.processors.KeepOnlySpecifiedFields
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_12.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_13.json
    fields_to_keep:
      - source_lang
      - audio_filepath
      - segment_id
      - offset
      - duration
      - session_id
      - device_id
      - audio_type
      - audio_id

  # ========== STAGE 3: Transcription by slice (more accurate for segments) ==========
  - _target_: sdp.processors.FasterWhisperInference
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_13.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_14.json
    model_size_or_path: VoxAI/whisper-large-v3-polish-ct2
    num_devices: -1
    output_dir: ${output_dir}/${params.source_lang}/step_16
    inference:
      language: ${params.source_lang}
    save_timestamps_separately: false
    skip_corrupted_audios: true
    slice_by_offset: true  # Use offset and duration to slice audio

  # ========== STAGE 3: Keep transcription results ==========
  - _target_: sdp.processors.KeepOnlySpecifiedFields
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_14.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_15.json
    fields_to_keep:
      - source_lang
      - audio_filepath
      - segment_id
      - offset
      - duration
      - pred_text
      - session_id
      - device_id
      - audio_type
      - audio_id

  # ========== STAGE 3: Rename pred_text to text ==========
  - _target_: sdp.processors.RenameFields
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_15.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_16.json
    rename_fields:
      pred_text: text

  # ========== STAGE 3: Drop empty transcriptions ==========
  - _target_: sdp.processors.DropIfRegexMatch
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_16.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_17.json
    text_key: text
    regex_patterns:
      - '^\s*$'  # Empty or whitespace-only

  # ========== STAGE 3: Detect Whisper hallucinations ==========
  - _target_: sdp.processors.DetectWhisperHallucinationFeatures
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_17.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_18.json
    common_hall_file: ${sdp_dir}/dataset_configs/vox_pipeline/partials/common_phrases/${params.source_lang}.txt
    text_field: text

  # ========== STAGE 3: Filter hallucinated segments ==========
  - _target_: sdp.processors.LambdaExpression
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_18.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_19.json
    new_field: is_hallucinated
    expression: '(not entry.hall_repeated_ngrams) & (not entry.hall_long_word) & (not entry.hall_frequent_single_word)'
    filter: true

  # ========== STAGE 3: Clean hallucination fields ==========
  - _target_: sdp.processors.KeepOnlySpecifiedFields
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_19.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_20.json
    fields_to_keep:
      - source_lang
      - audio_filepath
      - segment_id
      - offset
      - duration
      - text
      - audio_type
      - device_id
      - session_id
      - audio_id
      
  # ========== STAGE 3: Menu-Aware Correction (Fuzzy Matching - First Pass) ==========
  # Initial menu item correction based on fuzzy matching for BK Poland
  - _target_: sdp.processors.menu_aware_correction.MenuAwareCorrection
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_20.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_21.json
    menu_vocabulary_file: ${sdp_dir}/dataset_configs/vox_pipeline/assets/vocabularies/bk_menu_vocabulary.json
    text_field: text
    corrected_field: text_menu_corrected
    fuzzy_threshold: 80
    context_window: 3
    save_corrections: true

  # ========== STAGE 3: Qwen LLM Menu Correction (Text-based, faster than Gemini audio) ==========
  # Uses Qwen3-8B to correct menu items and Polish model specific errors
  - _target_: sdp.processors.inference.llm.vllm.vllm.vLLMInference
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_21.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_22.json
    prompt_file: ${sdp_dir}/dataset_configs/vox_pipeline/partials/menu_correction_prompts/${params.source_lang}.yaml
    generation_field: llm_corrected_text
    model:
      model: Qwen/Qwen3-8B
      tensor_parallel_size: 1
      max_model_len: 2048  # Increased for menu context
      enable_chunked_prefill: true
      max_num_batched_tokens: 1024  # Increased for context
      enforce_eager: true
      dtype: float16
      gpu_memory_utilization: 0.90  # Slightly higher utilization
      max_num_seqs: 2  # Smaller batch for better quality
    inference:
      temperature: 0.1  # Very low for consistent spelling corrections
      top_p: 0.95  # High for coverage of menu vocabulary
      top_k: 50  # Increased for menu vocabulary coverage
      repetition_penalty: 1.0  # No penalty for consistent menu terms
      max_tokens: 2048
    apply_chat_template:
      tokenize: false
      add_generation_prompt: true
      enable_thinking: false  # CRITICAL: Disable thinking mode to prevent output contamination
    save_outputs: true
    output_dir: ${output_dir}/${params.source_lang}/llm_menu_corrections
    error_log_file: ${output_dir}/${params.source_lang}/qwen_llm_errors.json

  # ========== STAGE 3: Punctuation & Capitalization Restoration with Qwen ==========
  # Fix capitalization and punctuation AFTER spelling corrections
  - _target_: sdp.processors.inference.llm.vllm.vllm.vLLMInference
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_22.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_23.json
    generation_field: src_text
    prompt_file: ${sdp_dir}/dataset_configs/vox_pipeline/partials/pr_recovery_prompts/${params.source_lang}.yaml
    model:
      model: Qwen/Qwen3-8B
      tensor_parallel_size: 1
      max_model_len: 1024
      enable_chunked_prefill: true
      max_num_batched_tokens: 512
      enforce_eager: true
      dtype: float16
      gpu_memory_utilization: 0.9
      max_num_seqs: 4
    inference:
      temperature: 0.3
      top_p: 0.8
      top_k: 20
      repetition_penalty: 1.05
      max_tokens: 2048
    apply_chat_template:
      tokenize: false
      add_generation_prompt: true
      enable_thinking: false

  # ========== STAGE 3: Clean Qwen Generation Output ==========
  - _target_: sdp.processors.CleanQwenGeneration
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_23.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_24.json
    text_field: llm_corrected_text  # Original text to keep
    generation_field: src_text  # Qwen output to clean

  # ========== STAGE 3: Text Normalization with Regex ==========
  - _target_: sdp.processors.SubRegex
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_24.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_25.json
    text_key: src_text  # Apply to Qwen-processed text
    regex_params_yaml: ${sdp_dir}/dataset_configs/vox_pipeline/partials/subregex_params/${params.use_regex}.yaml

  # ========== STAGE 3: Drop intermediate text fields ==========
  - _target_: sdp.processors.DropSpecifiedFields
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_25.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_26.json
    fields_to_drop:
      - text
      - text_menu_corrected
      - menu_corrections
      - num_corrections
      - gemini_corrections
      - llm_corrected_text

  # ========== STAGE 3: Rename final text field ==========
  - _target_: sdp.processors.RenameFields
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_26.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_27.json
    rename_fields:
      src_text: text  # Final cleaned text
      offset: source_audio_offset
      
  # ========== STAGE 3: Add constant metadata fields ==========
  - _target_: sdp.processors.AddConstantFields
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_27.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_28.json
    fields:
      dataset: ${brand}_${country}_drive_thru
      language: ${params.source_lang}
    
  # ========== STAGE 3: Final field selection ==========
  - _target_: sdp.processors.flexible_field_keeper.FlexibleKeepFields
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_28.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_29.json
    fields_to_keep:
      - audio_filepath
      - text
      - duration
      - source_audio_offset
      - segment_id
      - audio_type
      - device_id
      - session_id
      - audio_id
      - dataset
      - language
      - gemini_confidence
      - gemini_correction_made

  # ========== STAGE 3: Convert to WebDataset (TAR archives with wav/json pairs) ==========
  - _target_: sdp.processors.convert_to_webdataset.ConvertToWebDataset
    input_manifest_file: ${output_dir}/${params.source_lang}/manifest_29.json
    output_manifest_file: ${output_dir}/${params.source_lang}/manifest_30.json
    output_dir: ${output_dir}/${params.source_lang}/webdataset
    shard_size: 100  # Files per shard
    split: train
    prefix: shard
    shuffle: true
    shuffle_seed: 42
    slice_with_offset: true  # Extract audio segments
    speaker_field: speaker  # Include in metadata
    include_metadata: true